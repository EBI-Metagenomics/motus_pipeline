manifest {
    mainScript = "main.nf"
}

plugins {
    id 'nf-amazon'
    id 'nf-validation@1.1.3' // Validation of pipeline parameters and creation of an input channel from a sample sheet
}

params {
    outdir = "motus_pipeline_results"
    workdir = "motus-pipeline_workdir"
    // --- dbs
    databases = 'nextflow-autodownload-databases'
    download_ftp_path = 'ftp://ftp.ebi.ac.uk/pub/databases/metagenomics/pipeline-5.0/ref-dbs'

    // --- INPUTS
    sample_name = ''
    reads_accession = ''
    single_end = ''
    paired_end_forward = ''
    paired_end_reverse = ''
    mode = '' // single or paired

    // --- fastp filtering ---
    length_filter = 10
    polya_trim = 10
    qualified_quality_phred = 15
    unqualified_percent_limit = 10

    // --- REFERENCE GENOME --- //
    // TODO: we need to list all the genomes we can make
    //       available on the FTP, each one with the corresponding
    //       version and instructions to reconstruct.
    decontamination_indexes_folder = 'hg38'
    decontamination_reference_index = 'hg38.fa'

    // --- custom reference //
    reference_genome = false
    reference_genome_name = false

    // --- CMSEARCH ---
    cmsearch_db_name = 'rfam_models'
    ribosomal_model_path = 'ribosomal_models/ribo.cm'
    ribosomal_claninfo_path = 'ribosomal_models/ribo.claninfo'
    other_model_path = 'other_models'
    other_claninfo_path = 'other_models/other.claninfo'

    // --- mOTUs
    motus_db_name = 'db_mOTU'

    // --- MAPSEQ ---
    // --- download values
    silva_ssu_db_name = 'silva_ssu-20200130'
    ssu_db_fasta = "SSU.fasta"
    ssu_db_tax = "slv_ssu_filtered2.txt"
    ssu_db_otu = "ssu2.otu"
    ssu_label = "SSU"

    silva_lsu_db_name = 'silva_lsu-20200130'
    lsu_db_fasta = "LSU.fasta"
    lsu_db_tax = "slv_lsu_filtered2.txt"
    lsu_db_otu = "lsu2.otu"
    lsu_label = "LSU"

    // --- custom ssh/lsu database --- //
    ssu_db = false
    lsu_db = false
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Load AWS config with asw profile
includeConfig 'config/aws.config'

// Load codon config
includeConfig 'codon.config'

// Load modules.config
includeConfig 'modules.config'

profiles {
    conda {
        conda.enabled          = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        conda.enabled          = false
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
        apptainer.enabled      = false
    }

    local {
        docker.enabled         = true
        docker.autoMounts      = true
        docker.fixOwnership    = true
        executor.name          = "local"
        executor.cpus          = 2
        includeConfig 'config/local.config'
    }
}

// Set default registry for Apptainer, Docker, Podman and Singularity independent of -profile
// Will not be used unless Apptainer / Docker / Podman / Singularity are enabled
// Set to your registry if you have a mirror of containers
apptainer.registry   = 'quay.io'
docker.registry      = 'quay.io'
podman.registry      = 'quay.io'
singularity.registry = 'quay.io'


// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
